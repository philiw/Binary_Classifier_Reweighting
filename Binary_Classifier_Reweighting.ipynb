{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f403c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import mplhep as hep\n",
    "from comet_ml import Experiment\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85623ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-factor:  0.7826885718054716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nplt.hist(rw_weights_eft, bins=100, label=\"Reweighted weights EFT\")\\nplt.hist(weights_target, bins=100, label=\"Reweighted weights Target\")\\nplt.legend()\\nplt.show()\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"C:/Users/phili/Desktop/Studium/6. Semester/Semesterarbeit/dataset\"\n",
    "\n",
    "df_target = ak.from_parquet(folder+'/ttHTobb_2018_test.parquet')\n",
    "df_eft_tbarlnutqq = ak.from_parquet(folder+'/ttHTobb_EFT_tbarlnutqq_2018_test.parquet')\n",
    "df_eft_tbarqqtlnu = ak.from_parquet(folder+'/ttHTobb_EFT_tbarqqtlnu_2018_test.parquet')\n",
    "\n",
    "df_eft = ak.concatenate([df_eft_tbarlnutqq, df_eft_tbarqqtlnu])\n",
    "\n",
    "def reweight(weights_eft, weights_target):\n",
    "    weights_eft.to_numpy(); weights_target.to_numpy()\n",
    "    \n",
    "    A = np.sum(weights_target)/np.sum(weights_eft)\n",
    "        \n",
    "    return A, A*weights_eft\n",
    "\n",
    "weights_eft = df_eft.weight\n",
    "weights_target = df_target.weight\n",
    "\n",
    "A, weights_eft = reweight(weights_eft, weights_target)\n",
    "df_eft = ak.with_field(df_eft, weights_eft, \"weight\")\n",
    "\n",
    "\n",
    "print(\"K-factor: \", A)\n",
    "\"\"\"\n",
    "plt.hist(rw_weights_eft, bins=100, label=\"Reweighted weights EFT\")\n",
    "plt.hist(weights_target, bins=100, label=\"Reweighted weights Target\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "752f6fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def standardize_feature(col: np.ndarray, transform: str = None):\n",
    "    \"\"\"\n",
    "    Apply optional transform to col, then z-score:\n",
    "      - transform=\"log1p\": replace col -> log(col + 1)\n",
    "      - transform=None: leave col as is\n",
    "    Returns the transformed, zero-mean, unit-std array.\n",
    "    \"\"\"\n",
    "    # 1) optional transform\n",
    "    if transform == \"log1p\":\n",
    "        col = np.log(col + 1)\n",
    "    # 2) compute mean & std\n",
    "    mu = np.mean(col)\n",
    "    sigma = np.std(col)\n",
    "    # 3) z-score\n",
    "    return (col - mu) / (sigma if sigma != 0 else 1.0)\n",
    "\n",
    "def build_X_and_standardize(df_combined, objects, fields, orders):\n",
    "    \"\"\"\n",
    "    Pull out raw arrays, standardize each (pt->log1p+z, eta->z, phi->z),\n",
    "    and stack into an (N, D) array.\n",
    "    \"\"\"\n",
    "    X_cols = []\n",
    "    for obj in objects:\n",
    "        for field in fields:\n",
    "            for order in orders:\n",
    "                # extract a 1d numpy array\n",
    "                raw = getattr(getattr(df_combined, obj), field)[:, order].to_numpy()\n",
    "                # pick transform type\n",
    "                if field == \"pt\":\n",
    "                    col = standardize_feature(raw, transform=\"log1p\")\n",
    "                else:\n",
    "                    col = standardize_feature(raw, transform=None)\n",
    "                X_cols.append(col)\n",
    "    # stack into (n_events, n_features)\n",
    "    return np.stack(X_cols, axis=1)\n",
    "\n",
    "# ——————————————————————————————\n",
    "# usage:\n",
    "\n",
    "# 1) label & concat as before\n",
    "df_target[\"label\"] = 1\n",
    "df_eft   [\"label\"] = 0\n",
    "df_combined = ak.concatenate([df_target, df_eft])\n",
    "\n",
    "# 2) define your objects/fields/orders\n",
    "objects = [\"top\", \"antitop\", \"lepton_gen\", \"lepton_reco\", \"higgs\"]\n",
    "fields  = [\"pt\", \"eta\", \"phi\"]\n",
    "orders  = [0]\n",
    "length_features = len(objects)*len(fields)*len(orders)\n",
    "\n",
    "# 3) build standardized X\n",
    "X = build_X_and_standardize(df_combined, objects, fields, orders)\n",
    "y = df_combined.label.to_numpy()\n",
    "w = df_combined.weight.to_numpy()\n",
    "\n",
    "# 4) to torch\n",
    "X_torch = torch.tensor(X, dtype=torch.float32)\n",
    "y_torch = torch.tensor(y, dtype=torch.float32)\n",
    "w_torch = torch.tensor(w, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "648276f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/philiw/tthbb-reweighting/2bf3c19a766643c2b264ef05eb8e5cfb\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in 'c:\\\\Users\\\\phili\\\\Desktop\\\\Studium\\\\6. Semester\\\\Semesterarbeit\\\\Binary_Classifier_Reweighting' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
     ]
    }
   ],
   "source": [
    "# Initialize a Comet experiment\n",
    "experiment = Experiment(\n",
    "    api_key=\"s0G6qTP8E4YpcrewlNfry98cY\",\n",
    "    project_name=\"ttHbb-reweighting\",\n",
    "    workspace=\"philiw\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1706d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_out = nn.Linear(hidden_dim, 1)  # Output = 1 dimension (logit)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # No activation on the last layer, we'll apply sigmoid in the loss\n",
    "        return self.fc_out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab018aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10  # adjust as needed\n",
    "hidden_dim = 64  # hidden layer size\n",
    "batch_size = 2048  # adjust as needed\n",
    "learning_rate = 1e-4  # adjust as needed\n",
    "\n",
    "\n",
    "# Log hyperparameters\n",
    "experiment.log_parameters({\n",
    "    \"input_dim\": length_features,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"n_epochs\": n_epochs\n",
    "})\n",
    "\n",
    "\n",
    "n_events = len(X_torch)\n",
    "all_idx = np.arange(n_events)\n",
    "\n",
    "idx_train, idx_test = train_test_split(all_idx, test_size=0.5, random_state=42) # Optional: stratify\n",
    "\n",
    "# keep  convenience copy that contains ONLY the EFT rows inside the train fold\n",
    "eft_train_idx = idx_train[y[idx_train] == 0]\n",
    "target_train_idx = idx_train[y[idx_train] == 1]\n",
    "eft_test_idx = idx_test[y[idx_test] == 0]\n",
    "target_test_idx = idx_test[y[idx_test] == 1]\n",
    "\n",
    "X_train = X_torch[idx_train]\n",
    "y_train = y_torch[idx_train]\n",
    "w_train = w_torch[idx_train]\n",
    "\n",
    "X_test = X_torch[idx_test]\n",
    "y_test = y_torch[idx_test]\n",
    "w_test = w_torch[idx_test]\n",
    "\n",
    "# 2. Build train and test datasets\n",
    "train_dataset = TensorDataset(X_train, y_train, w_train)\n",
    "test_dataset  = TensorDataset(X_test,  y_test,  w_test)\n",
    "\n",
    "# 3. Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 4. (Optional) Log sizes\n",
    "experiment.log_metric(\"train_size\", len(train_dataset))\n",
    "experiment.log_metric(\"test_size\",  len(test_dataset))\n",
    "\n",
    "model = SimpleClassifier(input_dim=length_features, hidden_dim=hidden_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "bce_loss = nn.BCEWithLogitsLoss(reduction='none')  # We'll do weighting manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d731081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(model, x, y, w):\n",
    "    logits = model(x)  # shape: [batch_size, 1]\n",
    "    # BCE loss with optional event weight\n",
    "    raw_loss = bce_loss(logits.squeeze(), y)\n",
    "    # multiply by MC weights, then average\n",
    "    loss = (raw_loss * w).mean()\n",
    "    return loss\t\n",
    "\n",
    "def train_model(model, loader, optimizer, n_epochs):\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for batch_x, batch_y, batch_w in loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss = calculate_loss(model, batch_x, batch_y, batch_w)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_loss = epoch_loss / len(loader)\n",
    "        print(f\"[Epoch {epoch}] average loss = {avg_loss:.7f}\")\n",
    "        experiment.log_metric(\"average_loss\", avg_loss, step=epoch)\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            # Evaluate the model on the training set every 5 epochs\n",
    "\n",
    "            f_eft, reweighted_wts, reweighting_factors = evaluate_model_on_eft(model, X_train, y_train, w_train)\n",
    "            do_plots(f_eft, reweighted_wts, reweighting_factors, eft_indices=eft_train_idx, target_indices=target_train_idx, step=epoch)\n",
    "\n",
    "    # Save the model and log it to Comet\n",
    "    torch.save(model.state_dict(), \"simple_classifier.pth\")\n",
    "    experiment.log_model(\"simple_classifier\", \"simple_classifier.pth\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model_on_eft(model, X, y, w):\n",
    "    model.eval()\n",
    "\n",
    "    # Grab only EFT events from the combined dataset\n",
    "    EFT_mask = y == 0\n",
    "    eft_xft = X[EFT_mask]\n",
    "    w_mc_eft = w[EFT_mask]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits_eft = model(eft_xft).squeeze()\n",
    "        f_eft = torch.sigmoid(logits_eft)  # f(x)\n",
    "        w_new = f_eft / (1.0 - f_eft)      # w(x) = f/(1-f)\n",
    "\n",
    "    # Final reweighted MC weights for EFT:\n",
    "    reweighted_wts = w_mc_eft * w_new\n",
    "    \n",
    "    return f_eft, reweighted_wts, w_new\n",
    "\n",
    "def plot_dist_f(f_eft, eft_indices = None, epoch=-1):\n",
    "    masked_weights_eft = df_combined.weight[eft_indices].to_numpy()\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot()\n",
    "    ax.hist(f_eft, bins=50, weights=masked_weights_eft)\n",
    "    ax.set_xlabel(\"f(x)\")\n",
    "    ax.set_ylabel(\"Weighted Events\")\n",
    "    filename = f\"distribution_f.png\"\n",
    "    #plt.show()  # Optionally, you can omit this in non-interactive scripts\n",
    "    if epoch == -1:\n",
    "        plt.savefig(filename)\n",
    "        experiment.log_image(filename, name=filename)\n",
    "    else:\n",
    "        plt.savefig(filename)\n",
    "        experiment.log_image(filename, name=filename, step=epoch)\n",
    "    plt.close(fig)\n",
    "\n",
    "def plot_dist_w(reweighting_factors, eft_indices = None, epoch=-1):\n",
    "    masked_weights_eft = df_combined.weight[eft_indices].to_numpy()\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot()\n",
    "    ax.hist(reweighting_factors, bins=50, weights=masked_weights_eft)\n",
    "    ax.set_xlabel(\"w(x)\")\n",
    "    ax.set_ylabel(\"Weighted Events\")\n",
    "    filename = f\"distribution_w.png\"\n",
    "    #plt.show()  # Optionally, you can omit this in non-interactive scripts\n",
    "    if epoch == -1:\n",
    "        plt.savefig(filename)\n",
    "        experiment.log_image(filename, name=filename)\n",
    "    else:\n",
    "        plt.savefig(filename)\n",
    "        experiment.log_image(filename, name=filename, step=epoch)\n",
    "    plt.close(fig)\n",
    "\n",
    "def get_bins_and_scale(object, field, num_bins=50):\n",
    "    if field == 'pt':\n",
    "        if object == 'top' or object == 'antitop' or object == 'higgs':\n",
    "            return np.logspace(1.3, 2.9, num_bins), 'log'\n",
    "        if object == 'lepton_gen' or object == 'lepton_reco':\n",
    "            return np.logspace(1.4, 2.7, num_bins), 'log'\n",
    "    elif field == 'eta':\n",
    "        if object == 'lepton_gen' or object == 'lepton_reco':\n",
    "            return np.linspace(-3, 3, num_bins), 'linear'\n",
    "        else:\n",
    "            return np.linspace(-4, 4, num_bins), 'linear'\n",
    "    elif field == 'phi':\n",
    "        return np.linspace(-np.pi, np.pi, num_bins), 'linear'\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown field: {field}\")\n",
    "\n",
    "def plot_1d_dist(reweighted_wts, eft_indices=None, target_indices = None, epoch=-1): #Default select all events in \n",
    "    # Loop over each combination\n",
    "    for obj in objects:\n",
    "        for field in fields:\n",
    "\n",
    "            bins, scale = get_bins_and_scale(obj, field)\n",
    "            \n",
    "            for order in orders:\n",
    "                # Extract the appropriate variable from the EFT and Target data, select indices based on what the model evaluated on\n",
    "                eft_variable = getattr(getattr(df_combined, obj), field)[:, order][eft_indices]\n",
    "                target_variable = getattr(getattr(df_combined, obj), field)[:, order][target_indices]\n",
    "                masked_weights_eft = df_combined.weight[eft_indices]\n",
    "                masked_weights_target = df_combined.weight[target_indices]\n",
    "\n",
    "                # Define your histogram bins (you may wish to adjust these per variable)\n",
    "                bin_centers = 0.5 * (bins[1:] + bins[:-1])\n",
    "\n",
    "                # Compute the histograms\n",
    "                \n",
    "                hist_eft, _    = np.histogram(eft_variable, bins=bins, weights=masked_weights_eft)\n",
    "                hist_rw_eft, _ = np.histogram(eft_variable, bins=bins, weights=reweighted_wts.numpy())\n",
    "                hist_target, _ = np.histogram(target_variable, bins=bins, weights=masked_weights_target)\n",
    "\n",
    "                # Create the figure with a top and bottom panel\n",
    "                fig, (ax_top, ax_bot) = plt.subplots(\n",
    "                    2, 1, figsize=(10, 10),\n",
    "                    gridspec_kw={'height_ratios': [5, 2]}\n",
    "                )\n",
    "\n",
    "                # Top panel: draw the histograms\n",
    "                ax_top.stairs(hist_eft, bins, label=\"EFT data (unweighted)\", fill=False)\n",
    "                ax_top.stairs(hist_rw_eft, bins, label=f\"Reweighted EFT ({order})\", fill=False)\n",
    "                ax_top.stairs(hist_target, bins, label=\"Target data\", fill=False)\n",
    "                ax_top.set_xscale(scale)\n",
    "                ax_top.set_xlabel(f\"{obj}.{field}\")\n",
    "                ax_top.set_ylabel(\"Weighted events\")\n",
    "                ax_top.set_title(f\"Histogram of {obj}.{field}\\n(reweighting: {order})\")\n",
    "                ax_top.legend()\n",
    "\n",
    "                # Bottom panel: compute and plot the ratios\n",
    "                # Ratio of target to original EFT\n",
    "                ratio_old = np.where(hist_eft != 0, hist_target / hist_eft, np.nan)\n",
    "                # Ratio of target to reweighted EFT\n",
    "                ratio_rw = np.where(hist_rw_eft != 0, hist_target / hist_rw_eft, np.nan)\n",
    "\n",
    "                ax_bot.plot(bin_centers, ratio_old, 'o-', label=\"Original ratio\", markersize=3)\n",
    "                ax_bot.plot(bin_centers, ratio_rw, 'o-', label=f\"Reweighted ratio ({order})\", markersize=3)\n",
    "                ax_bot.set_xscale(scale)\n",
    "                ax_bot.axhline(1.0, color='gray', linestyle='--')\n",
    "                ax_bot.set_ylim(0.5, 1.5)\n",
    "                ax_bot.set_ylabel(\"Target / EFT\")\n",
    "                ax_bot.set_xlabel(f\"{obj}.{field}\")\n",
    "                ax_bot.legend(fontsize=10)\n",
    "\n",
    "                plt.tight_layout()\n",
    "\n",
    "                # Save and log the figure\n",
    "                filename = f\"1d_reweighting_{obj}_{field}_{order}.png\"\n",
    "                #plt.show()  # Optionally, you can omit this in non-interactive scripts\n",
    "                if epoch == -1:\n",
    "                    plt.savefig(filename)\n",
    "                    experiment.log_image(filename, name=filename)\n",
    "                else:\n",
    "                    plt.savefig(filename)\n",
    "                    experiment.log_image(filename, name=filename, step=epoch)\n",
    "                # Close the plot to free up memory before the next loop iteration\n",
    "                plt.close(fig)\n",
    "\n",
    "def plot_2d_dist(reweighted_wts, eft_indices=None, target_indices = None, epoch=-1):\n",
    "    for i, obj1 in enumerate(objects):\n",
    "        for j, obj2 in enumerate(objects):\n",
    "            if i >= j:\n",
    "                continue\n",
    "            for field1 in fields:\n",
    "                for field2 in fields:\n",
    "                    for order in orders:\n",
    "                        # get bins for the 2D histogram\n",
    "                        bins1, scale1 = get_bins_and_scale(obj1, field1, num_bins=20)\n",
    "                        bins2, scale2 = get_bins_and_scale(obj2, field2, num_bins=20)\n",
    "\n",
    "                        # extract EFT phase‐space coords\n",
    "                        eft_x = getattr(getattr(df_combined, obj1), field1)[:, order][eft_indices].to_numpy()\n",
    "                        eft_y = getattr(getattr(df_combined, obj2), field2)[:, order][eft_indices].to_numpy()\n",
    "                        target_x = getattr(getattr(df_combined, obj1), field1)[:, order][target_indices].to_numpy()\n",
    "                        target_y = getattr(getattr(df_combined, obj2), field2)[:, order][target_indices].to_numpy()\n",
    "                        masked_weights_eft = df_combined.weight[eft_indices]\n",
    "                        masked_weights_target = df_combined.weight[target_indices]\n",
    "                        \n",
    "                        # 5) make figure with one subplot per bin\n",
    "\n",
    "                        fig, axs = plt.subplots(1, 4, figsize=(32, 8))\n",
    "\n",
    "                        h_eft_result = axs[0].hist2d(\n",
    "                            eft_x, eft_y, bins=[bins1, bins2],\n",
    "                            weights=masked_weights_eft.to_numpy(), cmap='inferno'  \n",
    "                        )\n",
    "                        axs[0].set_xscale(scale1)\n",
    "                        axs[0].set_yscale(scale2)\n",
    "                        axs[0].set_title(\"EFT (unweighted)\")\n",
    "                        axs[0].set_xlabel(f\"{obj1}-{field1}\")\n",
    "                        axs[0].set_ylabel(f\"{obj2}-{field2}\")\n",
    "                        plt.colorbar(h_eft_result[3], ax=axs[0])\n",
    "                        \n",
    "                        # Reweighted EFT 2D histogram\n",
    "                        h_rew_result = axs[1].hist2d(\n",
    "                            eft_x, eft_y, bins=[bins1, bins2],\n",
    "                            weights=reweighted_wts, cmap='inferno'\n",
    "                        )\n",
    "                        axs[1].set_xscale(scale1)\n",
    "                        axs[1].set_yscale(scale2)\n",
    "                        axs[1].set_title(\"Reweighted EFT\")\n",
    "                        axs[1].set_xlabel(f\"{obj1}-{field1}\")\n",
    "                        axs[1].set_ylabel(f\"{obj2}-{field2}\")\n",
    "                        plt.colorbar(h_rew_result[3], ax=axs[1])\n",
    "                        \n",
    "                        # Target 2D histogram\n",
    "                        h_target_2d = np.histogram2d(\n",
    "                            target_x, target_y, bins=[bins1, bins2],\n",
    "                            weights=masked_weights_target.to_numpy()\n",
    "                        )[0]\n",
    "                        \n",
    "                        # 2D ratio: target / EFT (original)\n",
    "                        ratio_original = np.where(h_eft_result[0] != 0, h_target_2d / h_eft_result[0], np.nan)\n",
    "                        h3 = axs[2].pcolormesh(\n",
    "                            bins1, \n",
    "                            bins2, \n",
    "                            ratio_original.T,  # note transpose\n",
    "                            cmap='inferno',\n",
    "                            vmin=0.5,\n",
    "                            vmax=1.5,\n",
    "                            shading='auto'\n",
    "                        )\n",
    "                        axs[2].set_xscale(scale1)\n",
    "                        axs[2].set_yscale(scale2)\n",
    "                        axs[2].set_title(\"Ratio: Target / EFT\")\n",
    "                        axs[2].set_xlabel(f\"{obj1}-{field1}\")\n",
    "                        axs[2].set_ylabel(f\"{obj2}-{field2}\")\n",
    "                        plt.colorbar(h3, ax=axs[2])\n",
    "                        \n",
    "                        # 2D ratio: target / EFT (reweighted)\n",
    "                        ratio_rew = np.where(h_rew_result[0] != 0, h_target_2d / h_rew_result[0], np.nan)\n",
    "\n",
    "                        h4 = axs[3].pcolormesh(\n",
    "                            bins1, \n",
    "                            bins2,        \n",
    "                            ratio_rew.T, \n",
    "                            cmap='inferno',\n",
    "                            vmin=0.5,\n",
    "                            vmax=1.5,\n",
    "                            shading='auto'\n",
    "                        )\n",
    "                        axs[3].set_xscale(scale1)\n",
    "                        axs[3].set_yscale(scale2)\n",
    "                        axs[3].set_title(\"Ratio: Target / Reweighted EFT\")\n",
    "                        axs[3].set_xlabel(f\"{obj1}-{field1}\")\n",
    "                        axs[3].set_ylabel(f\"{obj2}-{field2}\")\n",
    "                        plt.colorbar(h4, ax=axs[3])\n",
    "                        \n",
    "                        plt.tight_layout()\n",
    "\n",
    "                        filename = f\"2d_reweighting_{obj1}_{field1}_{obj2}_{field2}.png\"\n",
    "                        plt.savefig(filename)\n",
    "                        experiment.log_image(filename, name=filename)\n",
    "                        plt.close(fig)\n",
    "\n",
    "def plot_weights_in_1d_phasespace(reweighting_factors, eft_indices=None):\n",
    "    n_bins = 3\n",
    "    quantiles = np.quantile(reweighting_factors, np.linspace(0, 1, n_bins + 1))\n",
    "    reweighting_factors_bins = np.digitize(reweighting_factors, bins=quantiles[1:-1], right=False)\n",
    "    labels = {\n",
    "        i: f\"{quantiles[i]:.2f}–{quantiles[i+1]:.2f}\"\n",
    "        for i in range(n_bins)\n",
    "    }\n",
    "\n",
    "    for i, obj in enumerate(objects):\n",
    "        for field in fields:\n",
    "            for order in orders:\n",
    "                # get bins for the 1D histogram\n",
    "                bins, scale = get_bins_and_scale(obj, field)\n",
    "\n",
    "                # extract EFT phase‐space coords\n",
    "                eft_x = getattr(getattr(df_combined, obj), field)[:, order][eft_indices].to_numpy()\n",
    "                w = df_combined.weight[eft_indices].to_numpy()\n",
    "\n",
    "                # 5) make figure with one subplot per bin\n",
    "                fig, axs = plt.subplots(\n",
    "                    1, n_bins,\n",
    "                    figsize=(4 * n_bins, 4),\n",
    "                    sharex=True, sharey=True\n",
    "                )\n",
    "\n",
    "                # 6) fill each subplot with a weighted histogram\n",
    "                for bin_idx in range(n_bins):\n",
    "                    mask = (reweighting_factors_bins == bin_idx)\n",
    "                    h = axs[bin_idx].hist(\n",
    "                        eft_x[mask],\n",
    "                        bins=bins,\n",
    "                        weights=w[mask],\n",
    "                        histtype='stepfilled',\n",
    "                        label=labels[bin_idx],\n",
    "                        alpha=0.5,\n",
    "                        color='blue'\n",
    "                    )\n",
    "                    axs[bin_idx].set_xscale(scale)\n",
    "                    axs[bin_idx].set_title(labels[bin_idx])\n",
    "                    if bin_idx == 0:\n",
    "                        axs[0].set_xlabel(field)\n",
    "                        axs[0].set_ylabel(\"Weighted events\")\n",
    "\n",
    "                \"\"\"\n",
    "                fig.suptitle(\n",
    "                    f\"{obj}-{field} histograms by w‐quantile\",\n",
    "                )\n",
    "                fig.colorbar(\n",
    "                    h[3], \n",
    "                    ax=axs.ravel().tolist(),\n",
    "                )\"\"\"\n",
    "\n",
    "                filename = f\"1d_phasespace_hist_{obj}_{field}.png\"\n",
    "                plt.savefig(filename)\n",
    "                experiment.log_image(filename, name=filename)\n",
    "                plt.close(fig)\n",
    "\n",
    "def plot_weights_in_2d_phasespace(reweighting_factors, eft_indices=None):\n",
    "    # --- your existing quantile‐binning code ---\n",
    "    n_bins = 3\n",
    "    quantiles = np.quantile(reweighting_factors, np.linspace(0, 1, n_bins + 1))\n",
    "    reweighting_factors_bins = np.digitize(reweighting_factors, bins=quantiles[1:-1], right=False)\n",
    "    labels = {\n",
    "        i: f\"{quantiles[i]:.2f}–{quantiles[i+1]:.2f}\"\n",
    "        for i in range(n_bins)\n",
    "    }\n",
    "\n",
    "    # 3) loop over object/field combinations\n",
    "    for i, obj1 in enumerate(objects):\n",
    "        for j, obj2 in enumerate(objects):\n",
    "            if i >= j:\n",
    "                continue\n",
    "            for field1 in fields:\n",
    "                for field2 in fields:\n",
    "                    for order in orders:\n",
    "                        # get bins for the 2D histogram\n",
    "                        bins1, scale1 = get_bins_and_scale(obj1, field1, num_bins=20)\n",
    "                        bins2, scale2 = get_bins_and_scale(obj2, field2, num_bins=20)\n",
    "\n",
    "                        # extract EFT phase‐space coords\n",
    "                        eft_x = getattr(getattr(df_combined, obj1), field1)[:, order][eft_indices].to_numpy()\n",
    "                        eft_y = getattr(getattr(df_combined, obj2), field2)[:, order][eft_indices].to_numpy()\n",
    "                        w = df_combined.weight[eft_indices].to_numpy()\n",
    "\n",
    "                        # 5) make figure with one subplot per bin\n",
    "                        fig, axs = plt.subplots(\n",
    "                            1, n_bins,\n",
    "                            figsize=(4 * n_bins, 4),\n",
    "                            sharex=True, sharey=True\n",
    "                        )\n",
    "\n",
    "                        # 6) fill each subplot with a weighted 2D histogram\n",
    "                        for bin_idx in range(n_bins):\n",
    "                            mask = (reweighting_factors_bins == bin_idx)\n",
    "                            h = axs[bin_idx].hist2d(\n",
    "                                eft_x[mask], eft_y[mask],\n",
    "                                bins=[bins1, bins2],\n",
    "                                weights=w[mask],\n",
    "                                cmap=plt.cm.viridis\n",
    "                            )\n",
    "                            axs[bin_idx].set_xscale(scale1)\n",
    "                            axs[bin_idx].set_yscale(scale2)\n",
    "                            axs[bin_idx].set_title(labels[bin_idx])\n",
    "                            if bin_idx == 0:\n",
    "                                axs[0].set_xlabel(field1)\n",
    "                                axs[0].set_ylabel(field2)\n",
    "\n",
    "                        \"\"\"\n",
    "                        fig.suptitle(\n",
    "                            f\"{obj1}-{field1} vs {obj2}-{field2} 2D histograms by w‐quantile\",\n",
    "                        )\n",
    "                        \"\"\"\n",
    "                        fig.colorbar(\n",
    "                            h[3], \n",
    "                            ax=axs.ravel().tolist(),\n",
    "                        )\n",
    "\n",
    "                        filename = f\"2d_phasespace_hist_{obj1}_{field1}_{obj2}_{field2}.png\"\n",
    "                        plt.savefig(filename)\n",
    "                        experiment.log_image(filename, name=filename)\n",
    "                        plt.close(fig)\n",
    "\n",
    "def do_plots(f_eft, reweighted_wts, reweighting_factors, eft_indices=None, target_indices=None, step=n_epochs):\n",
    "    # Plot the distribution of f(x) and w(x)\n",
    "    plot_dist_f(f_eft, eft_indices, step)\n",
    "    plot_dist_w(reweighting_factors, eft_indices, step)\n",
    "\n",
    "    # Plot the 1D distributions\n",
    "    plot_1d_dist(reweighted_wts, eft_indices, target_indices, step)\n",
    "    plot_2d_dist(reweighted_wts, eft_indices, target_indices, step)\n",
    "\n",
    "def train():\n",
    "    # Train the model\n",
    "    return  train_model(model, train_loader, optimizer, n_epochs)\n",
    "\n",
    "def evaluate(trained_model):\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_loss = calculate_loss(trained_model, X_test, y_test, w_test)\n",
    "    experiment.log_metric(\"test_loss\", test_loss)\n",
    "    f_eft, reweighted_wts, reweighting_factors = evaluate_model_on_eft(trained_model, X_test, y_test, w_test)\n",
    "    \n",
    "\n",
    "    do_plots(f_eft, reweighted_wts, reweighting_factors, eft_indices=eft_test_idx, target_indices=target_test_idx)\n",
    "\n",
    "    plot_weights_in_1d_phasespace(reweighting_factors, eft_test_idx)\n",
    "    plot_weights_in_2d_phasespace(reweighting_factors, eft_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97588e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] average loss = 0.0013485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phili\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\awkward\\_nplikes\\array_module.py:290: RuntimeWarning: divide by zero encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n",
      "c:\\Users\\phili\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\awkward\\_nplikes\\array_module.py:290: RuntimeWarning: invalid value encountered in divide\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n",
      "C:\\Users\\phili\\AppData\\Local\\Temp\\ipykernel_17856\\3149245249.py:230: RuntimeWarning: divide by zero encountered in divide\n",
      "  ratio_original = np.where(h_eft_result[0] != 0, h_target_2d / h_eft_result[0], np.nan)\n",
      "C:\\Users\\phili\\AppData\\Local\\Temp\\ipykernel_17856\\3149245249.py:248: RuntimeWarning: divide by zero encountered in divide\n",
      "  ratio_rew = np.where(h_rew_result[0] != 0, h_target_2d / h_rew_result[0], np.nan)\n",
      "C:\\Users\\phili\\AppData\\Local\\Temp\\ipykernel_17856\\3149245249.py:230: RuntimeWarning: invalid value encountered in divide\n",
      "  ratio_original = np.where(h_eft_result[0] != 0, h_target_2d / h_eft_result[0], np.nan)\n",
      "C:\\Users\\phili\\AppData\\Local\\Temp\\ipykernel_17856\\3149245249.py:248: RuntimeWarning: invalid value encountered in divide\n",
      "  ratio_rew = np.where(h_rew_result[0] != 0, h_target_2d / h_rew_result[0], np.nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] average loss = 0.0013469\n",
      "[Epoch 2] average loss = 0.0013465\n",
      "[Epoch 3] average loss = 0.0013461\n",
      "[Epoch 4] average loss = 0.0013460\n",
      "[Epoch 5] average loss = 0.0013456\n",
      "[Epoch 6] average loss = 0.0013454\n",
      "[Epoch 7] average loss = 0.0013454\n",
      "[Epoch 8] average loss = 0.0013452\n",
      "[Epoch 9] average loss = 0.0013450\n"
     ]
    }
   ],
   "source": [
    "trained_model = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ea2ef6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phili\\AppData\\Local\\Temp\\ipykernel_17856\\3149245249.py:230: RuntimeWarning: divide by zero encountered in divide\n",
      "  ratio_original = np.where(h_eft_result[0] != 0, h_target_2d / h_eft_result[0], np.nan)\n",
      "C:\\Users\\phili\\AppData\\Local\\Temp\\ipykernel_17856\\3149245249.py:230: RuntimeWarning: invalid value encountered in divide\n",
      "  ratio_original = np.where(h_eft_result[0] != 0, h_target_2d / h_eft_result[0], np.nan)\n",
      "C:\\Users\\phili\\AppData\\Local\\Temp\\ipykernel_17856\\3149245249.py:248: RuntimeWarning: divide by zero encountered in divide\n",
      "  ratio_rew = np.where(h_rew_result[0] != 0, h_target_2d / h_rew_result[0], np.nan)\n",
      "C:\\Users\\phili\\AppData\\Local\\Temp\\ipykernel_17856\\3149245249.py:248: RuntimeWarning: invalid value encountered in divide\n",
      "  ratio_rew = np.where(h_rew_result[0] != 0, h_target_2d / h_rew_result[0], np.nan)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : supporting_paint_9772\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/philiw/tthbb-reweighting/2bf3c19a766643c2b264ef05eb8e5cfb\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     average_loss [10] : (0.0013449564283850776, 0.0013484824675607024)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [231]        : (0.001315489411354065, 0.0013864203356206417)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_loss         : 0.0013459909241646528\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_size         : 471671\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_size        : 471670\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_size    : 2048\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hidden_dim    : 64\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     input_dim     : 15\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     learning_rate : 0.0001\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     n_epochs      : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 426\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (23.58 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "evaluate(trained_model)\n",
    "\n",
    "experiment.end()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
